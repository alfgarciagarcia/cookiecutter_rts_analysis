{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## {{cookiecutter.project_name}}\n",
    "\n",
    "{{cookiecutter.description}}\n",
    "\n",
    "### Data Sources\n",
    "- file1 : Description of where this file came from\n",
    "\n",
    "### Changes\n",
    "- {% now 'utc', '%m-%d-%Y' %} : Started project"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import glob\n",
    "import datetime as dt\n",
    "import pickle\n",
    "import os\n",
    "from pandas import ExcelWriter\n",
    "import re\n",
    "from zipfile import ZipFile\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import datetime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def categorize_columns(df, numunique= 205):\n",
    "    '''clean names of columns and caegorize object columns if unique is less than , numunique\n",
    "       downcast for int and floats'''\n",
    "    # https://stackoverflow.com/questions/30763351/removing-space-in-dataframe-python\n",
    "    df.columns = [x.strip() for x in df.columns]\n",
    "    df.rename(columns = lambda x: x.replace(\" \",\"_\"), inplace= True)\n",
    "    df.rename(columns = lambda x: x.replace(\".\",\"_\"), inplace= True)\n",
    "    df.rename(columns = lambda x: x.replace(\"&\",\"and\"), inplace= True)\n",
    "    df.rename(columns = lambda x: x.replace(\"(\",\"\"), inplace= True)\n",
    "    df.rename(columns = lambda x: x.replace(\")\",\"\"), inplace= True)\n",
    "    df.rename(columns = lambda x: x.replace(\"/\",\"\"), inplace= True)\n",
    "    df.rename(columns = lambda x: x.replace(\"-\",\"_\"), inplace= True)\n",
    "    df.rename(columns = lambda x: x.replace(\"+\",\"_plus_\"), inplace= True)\n",
    "    for y in df.columns:\n",
    "        #categorize columns\n",
    "        if df[y].dtype == np.object:\n",
    "            if len(df[y].unique()) <= numunique:\n",
    "                print('converted ' + y + ' ' +str(df[y].dtype) + ' records=' + str(len(df[y].unique())))\n",
    "                df[y] = df[y].astype('category')\n",
    "        elif(df[y].dtype == np.float64 or df[y].dtype == np.int64):\n",
    "            df[y] = pd.to_numeric(df[y], downcast='unsigned')\n",
    "            print('DOWNCAST ' +  y + ' ' +str(df[y].dtype))\n",
    "    return df\n",
    "\n",
    "def add_business_days(from_date, ndays):\n",
    "    '''Consider weekends when add days to a date'''\n",
    "    business_days_to_add = abs(ndays)\n",
    "    current_date = from_date\n",
    "    sign = ndays/abs(ndays)\n",
    "    while business_days_to_add > 0:\n",
    "        current_date += datetime.timedelta(sign * 1)\n",
    "        weekday = current_date.weekday()\n",
    "        if weekday >= 5: # sunday = 6\n",
    "            continue\n",
    "        business_days_to_add -= 1\n",
    "    return current_date"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### File Locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fileticketsname = input('Tickets file name: ')\n",
    "fileappsname = input('Apps file name: ')\n",
    "print(os.getcwd())\n",
    "originalpath = (os.getcwd())\n",
    "print(originalpath)\n",
    "\n",
    "os.chdir(originalpath)\n",
    "#os.chdir('..')\n",
    "path = os.getcwd()\n",
    "print(path)\n",
    "\n",
    "#filename = os.path.join(path, 'data','Power - Tickets - 2018 - v2.1-2.xlsx')\n",
    "filename = os.path.join(path, 'data','raw',fileticketsname)\n",
    "fileapps = os.path.join(path, 'data', 'raw', fileappsname)\n",
    "\n",
    "#outputfiles\n",
    "today = datetime.datetime.today()\n",
    "directory_name = '{{cookiecutter.directory_name}}'\n",
    "fileoriginaltickets = os.path.join(path, 'data','processed',\n",
    "                                   directory_name + '_tickets{:%m%d%y}.pkl').format(today)\n",
    "fileoriginalapps = os.path.join(path, 'data','processed',\n",
    "                                directory_name + '_apps{:%m%d%y}.pkl').format(today)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read files from Excel or CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if it is a CSV file ->tickets_file = pd.read_csv(filename)\n",
    "tickets_file = pd.ExcelFile(filename, \n",
    "                            converters= {'opened_at': pd.to_datetime, 'closed_at': pd.to_datetime})\n",
    "print(tickets_file.sheet_names)\n",
    "#get list of countries ina dataframe\n",
    "\n",
    "#read applications file\n",
    "apps_file = pd.ExcelFile(fileapps)\n",
    "print(apps_file.sheet_names)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sheetname= input('Sheet to load for tickets: ')\n",
    "tickets_final = tickets_file.parse(sheetname, skiprows=0)\n",
    "print(len(tickets_final))\n",
    "\n",
    "sheetname= input('Sheet to load foro apps: ')\n",
    "apps_final = apps_file.parse(sheetname, skiprows=0)\n",
    "print(len(apps_final))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Column Cleanup\n",
    "\n",
    "- Remove all leading and trailing spaces\n",
    "- Get columns names and determine columns to rename df.columns\n",
    "- Rename the columns for consistency.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#clean name columns, categorize columns, downcast columns\n",
    "tickets_final= categorize_columns(tickets_final)\n",
    "apps_final= categorize_columns(apps_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_to_rename = {'col1': 'New_Name'}\n",
    "tickets_final.rename(columns=cols_to_rename, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tickets_final.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean Up Data Types"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Manipulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save output file into processed directory\n",
    "Save a file in the processed directory that is cleaned properly. It will be read in and used later for further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save file a pkl for fast access\n",
    "tickets_final.to_pickle(fileoriginaltickets, 'gzip')\n",
    "print('original tickets file saved as {}'.format(fileoriginaltickets))\n",
    "\n",
    "#save file a pkl for fast access\n",
    "apps_final.to_pickle(fileoriginalapps, 'gzip')\n",
    "print('original apps file saved as {}'.format(fileoriginalapps))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
